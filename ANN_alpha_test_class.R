rm(list = ls())

set.seed(500)
library(MASS)
data <- Boston
#View(Boston)

apply(data,2,function(x) sum(is.na(x))) #2 represents rows

index <- sample(1:nrow(data), round(0.75*nrow(data)))

train <- data[index,]
test <- data[-index,]

lm.fit <- glm(medv~., data = train)
summary(lm.fit)

pr.lm <- predict(lm.fit, test)

MSE.lm <- sum((pr.lm - test$medv)^2)/nrow(test)

head(data)

maxs <- apply(data, 2, max)  #2 represents rows
maxs
mins <- apply(data, 2, min)
mins

head(scale(data, center = mins, scale = maxs - mins))
scaled <- as.data.frame(scale(data, center = mins, scale = maxs - mins))

train_ <- scaled[index,]
test_ <- scaled[-index,]

#install.packages("neuralnet")
library(neuralnet)
n <- names(train_)
n
paste(n[n != "medv"], collapse = "+")
f <- as.formula(paste("medv ~", paste(n[n != "medv"], collapse = "+")))
f

n <- names(train_)
n
paste(n[n != "medv"], collapse = "+")
f <- as.formula(paste("medv ~", paste(n[n != "medv"], collapse = "+")))
f

nn <- neuralnet(f, data = train_, hidden = c(5,3), linear.output = T)
pr.nn <- compute(nn, test_[,1:13])

pr.nn_ <- pr.nn$net.result*(max(data$medv)- min(data$medv)) + min(data$medv)

test.r <- (test_$medv)*(max(data$medv)-min(data$medv))+
  min(data$medv)

MSE.nn <- sum((test.r - pr.nn_)^2)/nrow(test_)
MSE.nn

print(paste(MSE.lm,MSE.nn))

par(mfrow=c(1,2))
plot(test$medv,pr.nn_,col='red',main='Real vs predicted NN',pch=18,cex=0.7)

abline(0,1,lwd=2)
legend('bottomright',legend = 'NN',pch = 18,col='red',bty = 'n')

plot(test$medv,pr.lm,col='blue',main = 'Real Vs predicted lm',pch=18,cex=0.7)
abline(0,1,lwd=2)
legend('bottomright',legend = 'LM',pch = 18,col='blue',bty = 'n',cex = .95)

par(mfrow=c(1,1))
plot(test$medv,pr.nn_,col='red',main = 'Real vs predicted NN & LM',pch=18,cex=0.7)
points(test$medv,pr.lm,col='blue',pch=18,cex=0.7)

abline(0,1,lwd=2)
legend('bottomright',legend = c('NN','LM'),pch = 18,col = c('red','blue'))

library(boot)
set.seed(200)
lm.fit <- glm(medv~., data = data)
cv.glm(data,lm.fit, K=10)$delta[1]

set.seed(450)
cv.error <- NULL
k <- 10

library(plyr)
pbar <- create_progress_bar('text')
pbar$init(k)

for(i in 1:k)
{
  index <- sample(1:nrow(data),round(0.9*nrow(data)))
  train.cv <- scaled[index, ]
  test.cv <- scaled[-index, ]
  
  nn <- neuralnet(f, data = train.cv, hidden = c(5,2), linear.output = T)
  pr.nn <- compute(nn,test.cv[, 1:13])
  pr.nn <- pr.nn$net.result*(max(data$medv) - min(data$medv)) + min(data$medv)
  test.cv.r <- (test.cv$medv)*(max(data$medv)-min(data$medv)) + min(data$medv)
  cv.error[i] <- sum((test.cv.r - pr.nn)^2) / nrow(test.cv)
  pbar$step()
}

mean(cv.error)
cv.error